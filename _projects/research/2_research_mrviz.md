---
layout: page
title: MRViz
description: "MRViz: Visualization System for Analyzing Reliability of CNN-based Deep Learning Model<p style='text-align:right; color:gray'>2021.03 - 2022.02</p>"

img: assets/img/projects/mrviz/mrviz-main.png
importance: 4
category: research
related_publications: false
---

#### [Key Concept]
With the emergence of Convolutional Neural Network (CNN), artificial intelligence-based applications have established a significant part of our daily lives. However, since general deep learning models are black-box, it is difficult to respond to vulnerabilities such as performance degradation caused by adversarial attacks. Model reliability threats can be catastrophic in safety-critical scenarios, such as carsâ€™ autonomous driving. Therefore, it is necessary to identify the cause of the threat and improve it to operate in the direction desired by humans. However, it is challenging to analyze deep learning models built without the intervention of human cognitive processes. We present MRViz, a visualization and interaction tool that can detect model reliability threats and derive improvement plans by analyzing their causes. With MRViz, users 1) discover the reliability threat in deep learning models by using the vulnerability to adversarial attack as a clue, and 2) utilize novel feature-based interpretability metrics to determine the difference between the human cognitive process and the model decision-making process. For evaluating the usability of MRViz, we conducted a case study, and we found valuable insights needed to improve the reliability threats of CNN-based deep learning models.

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/projects/mrviz/mrviz-main.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    MRViz, a visualization and interaction tool that can detect model reliability threats and derive improvement plans by analyzing their causes. With MRViz, users 1) discover the reliability threat in deep learning models by using the vulnerability to adversarial attack as a clue, and 2) utilize novel feature-based interpretability metrics to determine the difference between the human cognitive process and the model decision-making process.
</div>